---
title: "MIS-DESeq2"
author: "Sunit Jain"
date: "January 6, 2015"
output:
  html_document:
    dev: svg
    toc: yes
    toc_depth: 3
  pdf_document:
    fig_crop: no
    toc: yes
    toc_depth: 3
---



```{r dependencies, eval=FALSE, results='hide',  echo=FALSE}
#If you're unsure that you have all the pacakges required to run this workflow. Open the `Rmd` file in your favorite text editor (I used [RStudio](http://www.rstudio.com)) and change the next line from `eval=FALSE` to `eval=TRUE`. Now, when you run this workflow, the dependencies should be installed first.
package = function(p) {
  if (!p %in% installed.packages()){ 
  		install.packages(p, dep=T)
  }
}
package("gplots")
package("RColorBrewer")
package("vioplot")
package("ggplot2")
package("knitr")
package("dplyr")
package("tidyr")
package("readxl")
source("http://bioconductor.org/biocLite.R")
biocLite(c("DESeq2","BiocParallel","sva"))
```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
											echo=FALSE, warning=FALSE, message=FALSE)
```

```{r setup,  echo=FALSE}
## Setup
library(knitr)
workdir=getwd()
dataDir=paste(getwd(),"data", sep = "/")
gffFile=list.files(path=dataDir, pattern="*.gff", full.names=TRUE)
minRawCount=1 # at least these 2 conditions should have at least this raw count to consider that gene
topN=500 # number of genes in rank abundance plote
```

## Generate a read count matrix using `htseq-count`
Sample command:

`htseq-count -f bam -r name -t CDS -o scaffold.htseq.sam -i ID -q scaffold_sortedByName.bam all_combined.gff`

This command was run for each sample individually.

### Merging duplicate genes
I performed a self blast and looked at results that had a percent identity greater than 98%, query coverage greater than 96% and a minimum alignment length of 500 bases. Once I had this subset, I screened out the hits to exons since we won't be considering them for this experiment anyway. I was left with the following two gene pairs:

* scaffold_344578__MIS_1109813.1  scaffold_133898__MIS_10093600.14
* scaffold_219988__MIS_10179608.12  scaffold_555373__MIS_1172265.1

that had high enough similarity based on the thresholds mentioned above that their count data needed to be merged. The perl script `mergeCounts.pl` was run on each htseq-count output individually in order to accomplish this. Here is a sample command used for one of the htseq-count outputs:

`perl mergeCounts.pl -l realDuplicateGenes.list -tsv Day_1.htseqCount.tsv -o Day_1.htseqCount.merged.tsv`

where, realDuplicateGenes.list contains the two gene pairs mentioned above.


```{r readTSV, }
### Import Count files
sampleFiles=list.files(path=dataDir,pattern="*.htseqCount.merged.tsv", full.names=TRUE)
```

```{r conditions, }
library(DESeq2)
### Set Conditions
sampleCondition=c(rep("Day",3),rep("Night",3))
sampleName=c("Day_1","Day_2","Day_3", "Night_4", "Night_5", "Night_6")
sampleTable=data.frame(sampleName = sampleName, fileName=sampleFiles, condition=sampleCondition)
```

### Import Counts into DESeq2
Once we were satisfied with the genes and their counts. We imported the count data into DESeq2.
```{r deseq, cache=TRUE}
ddsHTSeq.all=DESeqDataSetFromHTSeqCount(sampleTable=sampleTable,design= ~ condition)
colData(ddsHTSeq.all)$condition<-factor(colData(ddsHTSeq.all)$condition, levels=c("Night","Day"))
```

## Reads per Sample
```{r readsPerSample}
colSums(counts(ddsHTSeq.all))
```

### Filtering the data
Get rid of genes which were not expressed in at least two samples. In other words, only keep genes with raw counts >=`r minRawCount` in at least two samples.
```{r dim}
keep=rowSums(counts(ddsHTSeq.all)>=minRawCount) >= 2
ddsHTSeq=ddsHTSeq.all[keep ,]
colSums(counts(ddsHTSeq))
```

### How many reads were removed?
```{r difference}
colSums(counts(ddsHTSeq.all))-colSums(counts(ddsHTSeq))
```

### How many genes were removed?
This reduced the dataset from `r dim(counts(ddsHTSeq.all))[1]` tags to about `r dim(counts(ddsHTSeq))[1]`. For the filtered tags, there is very little power to detect differential expression, so little information is lost by filtering. 

## Normalization

```{r reads_per_scaffold}
library(dplyr)
library(tidyr)
raw.counts=counts(ddsHTSeq.all) %>%
	as.data.frame(.) %>% 
	mutate(Gene=rownames(.), Genes=Gene) %>%
	separate(Gene, c("Scaffolds", "Locus"), sep="__") %>% 
	dplyr::select(Scaffolds, Genes, starts_with("Day"), starts_with("Night"))

rc.scaff=raw.counts %>% 
	group_by(Scaffolds) %>% 
	summarise_each(funs(sum), matches("_"))
```

### By Bin Coverage
$$ {Normalized Count}= \frac{\left( \frac{Gene Read Count}{Bin Read Count} \right)}{Bin Coverage} $$
```{r get_bins}
library(readxl)
scaff.bins=read_excel("data/Flux Binning Contig List (sunit).xlsx", sheet = 1) %>% dplyr::select(1:3)
scaff.bins$Bin=as.factor(scaff.bins$Bin)
colnames(scaff.bins)[1]=c("Scaffolds")
scaff.bins=scaff.bins %>% filter(Bin != "Unclassified")
bin.summary.num=scaff.bins %>%
	group_by(Bin) %>%
	summarise(Bin.Len=sum(Length))
bin.summary.num$Bin=as.character(bin.summary.num$Bin)
```

```{r bincov}
# Server Path: /geomicro/data21/MIS/gDNA/2012/Transfer
library(readr)
bin.cov=read_tsv("data/binCov.tsv") %>% select(-`DB-presence`)
colnames(bin.cov)=c("Bin", "Day_1", "Day_2", "Day_3", "Night_4", "Night_5", "Night_6")
```

```{r binSummary}
bin.desc=read_excel("data/Flux Binning Contig List (sunit).xlsx", sheet = 2) %>% dplyr::select(-7)
bin.desc$Domain=as.factor(bin.desc$Domain)
bin.desc$Phylum=as.factor(bin.desc$Phylum)
bin.desc$Class=as.factor(bin.desc$Class)
bin.desc$Order=as.factor(bin.desc$Order)
colnames(bin.desc)[6]=c("Genus.Species")
bin.desc$Genus.Species=as.factor(bin.desc$Genus.Species)

bin.summary=inner_join(bin.desc,bin.summary.num, by="Bin")
#rm(list=c("bin.summary.num", "bin.desc"))
#kable(head(bin.summary))
```

```{r reads_per_bin_per_sample}
reads.per.bin=inner_join(scaff.bins,rc.scaff, by="Scaffolds") %>% 
	group_by(Bin) %>% 
	summarise_each(funs(sum), matches("_"))

trpb=reads.per.bin %>% group_by(Bin) %>% mutate(Total=sum(Day_1,Day_2,Day_3,Night_4,Night_5,Night_6)) %>% ungroup() %>% arrange(desc(Total))
library(ggplot2)
trpb$Bin=factor(trpb$Bin, levels = trpb$Bin)
ggplot(trpb, aes(Bin,Total))+geom_bar(stat="identity")+ theme(axis.text.x = element_text(angle = 90, hjust = 0, vjust=0.5))
bins.of.interest=trpb %>% top_n(10,Total) %>% select(Bin)
```

#### Cyanobacteria
```{r cyanos}
bins.of.interest$Bin=as.character(bins.of.interest$Bin)
cyanos=bin.summary %>% filter(Phylum=="Cyanobacteria")
boi=data.frame(Bin=c(bins.of.interest$Bin, c("B20","B23","B27","B29","B57"), cyanos$Bin)) %>%
	distinct() %>% 
	left_join(.,bin.summary, by="Bin")
#kable(cyanos)

#cyano.scaffolds=inner_join(cyanos,scaff.bins, by="Bin") %>% dplyr::select(Bin,Scaffolds)
boi.scaffolds=inner_join(boi,scaff.bins, by="Bin") %>% dplyr::select(Bin,Scaffolds)
#cyano.bin.reads=inner_join(cyanos, reads.per.bin, by="Bin") %>% 
boi.bin.reads=inner_join(boi, reads.per.bin, by="Bin") %>% 
	group_by(Bin) %>% 
	mutate(Day.Total.Reads=sum(Day_1, Day_2, Day_3),
				 Night.Total.Reads=sum(Night_4, Night_5, Night_6),
				 Total.Reads=sum(Day.Total.Reads,Night.Total.Reads)) %>% 
	select(-matches("_"))

#cyano.bins=inner_join(cyano.bin.reads, bin.cov, by="Bin") %>% 
boi.bins=inner_join(boi.bin.reads, bin.cov, by="Bin") %>% 
	group_by(Bin) %>% 
	mutate(Day.Avg.Cov=mean(Day_1, Day_2, Day_3),
				 Night.Avg.Cov=mean(Night_4, Night_5, Night_6),
				 Avg.Cov=mean(Day.Avg.Cov,Night.Avg.Cov)) %>% 
	select(-matches("_")) %>% 
	ungroup() %>% 
	arrange(desc(Bin.Len))

kable(boi.bins, row.names=T)
```

```{r bin_normalization}
# 1. df= raw.counts + all.bin.reads + bin.coverage
## Add bin info to raw.counts
bin.norm.countData=inner_join(raw.counts,scaff.bins, by="Scaffolds") %>% 
	inner_join(., reads.per.bin, by="Bin") %>% 
	inner_join(.,bin.cov, by="Bin") %>% 
	mutate(n.Day1=((Day_1.x/Day_1.y)/Day_1), # (raw counts/all bin reads)/bin coverage
				 n.Day2=((Day_2.x/Day_2.y)/Day_2),
				 n.Day3=((Day_3.x/Day_3.y)/Day_3),
				 n.Night4=((Night_4.x/Night_4.y)/Night_4),
				 n.Night5=((Night_5.x/Night_5.y)/Night_5),
				 n.Night6=((Night_6.x/Night_6.y)/Night_6)
				 ) %>% 
	select(Genes,starts_with("n.")) %>% 
	replace(is.na(.),0) %>% 
	mutate(Total=rowSums(.[2:7])) %>% 
	arrange(desc(Total))

rownames(bin.norm.countData)=bin.norm.countData$Genes
bin.norm.countData=select(bin.norm.countData, -Genes, -Total)
colnames(bin.norm.countData)=c("Day_1","Day_2", "Day_3", "Night_4", "Night_5", "Night_6")
colSums(bin.norm.countData)

kable(head(bin.norm.countData))
#bin.norm.countData=normalizationFactors(dds,)
```
```{r func_violin_plot}
vplot = function(df=countData, title="Violin Plots for Normalized Counts"){
	library("vioplot")
	vioplot(df$Day_1,df$Day_2, df$Day_3, df$Night_4, df$Night_5, df$Night_6,
	        col="gold",
	        names=colnames(df)
					)
	title(title)	
}

## Plot
vplot(bin.norm.countData, "Violin Plot for Bin Normalized Counts")
```

### By relative library size.

In order to normalise the raw counts we will start by determining the relative library sizes, or size factors for each library. For example, if the counts of the expressed genes in one sample are, on average, twice as high as in another, the size factor for the first sample should be twice as large as the one for the other sample. These size factors can be obtained with the function `estimateSizeFactors`:

```{r counts}
dds=estimateSizeFactors(ddsHTSeq)
sizeFactors(dds)
```

### Normalized Counts

```{r counts_norm}
library("vioplot")
dds.ncounts=counts(dds, normalized=TRUE)
#head(dds.ncounts)
deseq.countData=data.frame(dds.ncounts)
vplot(deseq.countData)
```

## Rank Abundance
Plotting Rank Abundance for top `r topN` genes.

```{r func_rank_abundance}
grouped_counts=function(df=df,label=""){
	gc.df= df %>% 
		replace(is.na(.),0) %>% 
		select(starts_with(label)) %>% 
		mutate(Name=rownames(.)) %>% 
	  gather(ToD, Counts, -Name) %>%
	  group_by(Name) %>%
	  summarise(Totals=sum(Counts), Mean=mean(Counts), SE=sd(Counts)/sqrt(length(Counts))) %>%
		ungroup() %>% 
		top_n(topN, Mean) %>%
		mutate(Rank=row_number(desc(Mean)), Sample=label)
	
	return(gc.df)
}

rank_abundance = function(df=countData, title="Rank Abundance for Normalized counts"){
### Day Counts
library("tidyr")
library("dplyr")

### Day Counts
day.counts.ordered = grouped_counts(df,"Day")

### Night Counts
night.counts.ordered = grouped_counts(df,"Night")

### Day vs Night
# combined.counts=bind_rows(list(day.counts.ordered,night.counts.ordered)) %>%
# 	select(-Rank) %>% 
#   top_n(topN, Mean) %>% 
# 	mutate(RankByMean=row_number(desc(Mean))) %>%
# 	mutate(RankByName=min_rank(Name))
# combined.counts$Name= as.factor(combined.counts$Name)
# combined.counts$Sample= as.factor(combined.counts$Sample)

my.plot=plot_rank_abundance(day.counts.ordered,night.counts.ordered,title)

#return(list(day=day.counts.ordered, night=night.counts.ordered, combined=combined.counts, plot=my.plot))
return(list(day=day.counts.ordered, night=night.counts.ordered, plot=my.plot))
}

plot_rank_abundance = function(day=day.bin.norm,night=night.bin.norm,title=""){
	day.counts.ordered=day %>% replace(is.na(.),0) %>% filter(Totals > 0)
	night.counts.ordered=night %>% replace(is.na(.),0) %>% filter(Totals > 0)
	### Plot
	library(ggplot2)
	#my.plot=ggplot(na.omit(combined.counts), aes(RankByMean,Mean, color=Sample)) +
	my.plot=ggplot() +
	#  geom_line(aes(group=Name)) + 
		geom_point(data=day.counts.ordered, aes(Rank,Mean, color=Sample)) +
		#geom_errorbar(aes(ymax=Mean+SE, ymin=Mean-SE), data = day.counts.ordered) +
		geom_point(data=night.counts.ordered, aes(Rank,Mean, color=Sample)) +
		#geom_errorbar(aes(ymax=Mean+SE, ymin=Mean-SE), data = night.counts.ordered) +
		xlim(1,topN) +
	  scale_y_log10() +
		scale_color_brewer(palette = "Dark2") +
	  ylab("log10 Mean Counts")+
	  xlab("Combined Top Genes")+
		ggtitle(title) +
		theme_minimal()
	return(my.plot)
}
```

```{r}
 day.bin.norm=grouped_counts(bin.norm.countData,"Day")
# night.bin.norm=grouped_counts(bin.norm.countData,"Night")
# 	day.counts.ordered=day.bin.norm %>% replace(is.na(.),0)
# 	night.counts.ordered=na.omit(night.bin.norm) %>% replace(is.na(.),0)
# 	### Plot
# 	library(ggplot2)
# 	ggplot() +
# 		geom_point(data=day.counts.ordered, aes(Rank,Mean, color=Sample)) +
# 		geom_point(data=night.counts.ordered, aes(Rank,Mean, color=Sample)) +
# 		xlim(1,topN) +
# 	  scale_y_log10() +
# 		scale_color_brewer(palette = "Dark2") +
# 	  ylab("log10 Mean Counts")+
# 	  xlab("Combined Top Genes")+
# 		ggtitle("Test") +
# 		theme_minimal()
```


```{r rank_abundance_plots}
bin.norm.list=rank_abundance(bin.norm.countData, "Rank Abundance for Bin Coverage normalized counts")
bin.norm.list$plot
deseq.norm.list=rank_abundance(deseq.countData, "Rank Abundance for DESeq2 normalized counts")
deseq.norm.list$plot
```


```{r func_rank_abundance_by_bin}
rank_abundance_by_bin= function(bin, title){
	my.bin.norm.countData=inner_join(raw.counts,scaff.bins, by="Scaffolds") %>% 
		filter(Bin == bin) %>% 
		inner_join(., reads.per.bin, by="Bin") %>% 
		inner_join(.,bin.cov, by="Bin") %>% 
		mutate(n.Day1=((Day_1.x/Day_1.y)/Day_1),
					 n.Day2=((Day_2.x/Day_2.y)/Day_2),
					 n.Day3=((Day_3.x/Day_3.y)/Day_3),
					 n.Night4=((Night_4.x/Night_4.y)/Night_4),
					 n.Night5=((Night_5.x/Night_5.y)/Night_5),
					 n.Night6=((Night_6.x/Night_6.y)/Night_6)
					 ) %>% 
		select(Genes,starts_with("n.")) %>% 
		replace(is.na(.),0) %>% 
		mutate(Total=rowSums(.[2:7])) %>% 
		arrange(desc(Total))
	
	rownames(my.bin.norm.countData)=my.bin.norm.countData$Genes
	my.bin.norm.countData=select(my.bin.norm.countData, -Genes, -Total)
	colnames(my.bin.norm.countData)=c("Day_1","Day_2", "Day_3", "Night_4", "Night_5", "Night_6")
	colSums(my.bin.norm.countData)
	
	myObj=rank_abundance(my.bin.norm.countData,title)
	return(myObj)
}
```

### Rank Abundance by Bin
The following are Rank Abundance plots by bins of interest, normalized by Coverage as described in the formula above.

```{r rank_abundance_by_binCov_all_cyanos}
foreach.boi=boi.bins %>% 
	select(1:6) %>% 
	unite("title",2:6, sep=" > ")

bin.rank.abundance=apply(foreach.boi,1,function(x) rank_abundance_by_bin(x[1],paste(x[1],x[2], sep= " = ")))

# plots
for(row.num in 1:length(foreach.boi$Bin)){
	print(bin.rank.abundance[[row.num]]$plot)
}
```


```{r annotate_counts, cache=TRUE}
annotation=read.table("data/all_combined.products", sep="\t", quote="")
colnames(annotation)=c("Name", "IMG_Product","IMG_Source")
annotation$Name=as.character(annotation$Name)
```
```{r func_get_annotations}
get_annotations= function(day,night,count.data=bin.norm.countData){
	combined.union=data.frame()
	combined.union=as.data.frame(union(day$Name,night$Name))
	colnames(combined.union)="Name"
	combined.union$Name=as.character(combined.union$Name)
	
	tmp.countData=count.data
	tmp.countData$Name=rownames(tmp.countData)
	
	combined.union=left_join(combined.union, tmp.countData, by="Name")
	combined.union=left_join(combined.union, day, by="Name")
	combined.union=left_join(combined.union, night, by="Name")
	
	colnames(combined.union)=c("Name","Day_1","Day_2","Day_3","Night_4","Night_5","Night_6",
	                            "Day_Totals","Day_Mean","Day_SE","Day_Rank", "Del1",
	                            "Night_Totals","Night_Mean","Night_SE", "Night_Rank", "Del2")
	combined.union=combined.union %>% select(-c(Del1,Del2))
	combined.anno=left_join(combined.union, annotation, by="Name")
	
	return(combined.anno)
}
```

```{r write_counts}
# write
for(row.num in 1:length(foreach.boi$Bin)){
	bin.anno=data.frame()
	bin.anno=get_annotations(bin.rank.abundance[[row.num]]$day,bin.rank.abundance[[row.num]]$night)
	filename=paste("data/",foreach.boi$Bin[row.num],"_combined_raw_counts.tsv")
	write.table(bin.anno, file=filename,sep="\t", quote=FALSE, row.names = FALSE, na = "0");
	bin.anno=data.frame()
}
#write.table(combined.anno, file="data/combined_raw_counts.tsv",sep="\t", quote=FALSE, row.names = FALSE, na = "0");
```

## Differential Expression

### Removing Batch Effects
Differential expression was calculater using the DESeq2 wrapper function over 4 processors.

```{r deseq_wrapper,  }
library(BiocParallel)
register(MulticoreParam(4))

dat <- counts(dds, normalized=TRUE)
idx <- rowMeans(dat) > 1
dat <- dat[idx,]
mod <- model.matrix(~ condition, colData(dds))
mod0 <- model.matrix(~ 1, colData(dds))
library(sva)
svseq <- svaseq(dat, mod, mod0, n.sv=2)
ddsva=dds
ddsva$SV1=svseq$sv[, 1]
ddsva$SV2=svseq$sv[, 2]
design(ddsva)= ~SV1 + SV2 + condition
ddsva <- DESeq(ddsva)
```

## Results after removing batch effects
```{r results_wo_BE,  }
resva <- results(ddsva, parallel=T)
mcols(resva, use.names=TRUE)
summary(resva)
res=resva
dds=ddsva
```



### P-Value Histogram

Another useful diagnostic plot is the histogram of the p values.

```{r pval_hist, }
hist(res$pvalue[res$baseMean > 1], breaks=20, col="grey50", border="white")
```



## Significant Genes

Number of genes found to have significant differential expression:

```{r}
sigGenes=sum(res$padj < 0.1, na.rm=TRUE)
sigGenes
```

We subset the results table to these genes and then sort it by the log2 fold change estimate to get the significant genes with the strongest down-regulation.
```{r}
resSig <- subset(res, padj < 0.1)
head(resSig[ order( resSig$log2FoldChange ), ])
```

…and with the strongest upregulation. 
```{r}
# The order function gives the indices in increasing order, so a simple way to ask for decreasing order is to add a - sign. Alternatively, you can use the argument decreasing=TRUE.
head(resSig[ order( -resSig$log2FoldChange ), ])
```

### Summary Table

```{r write, }
resOrdered <- res[order(res$padj),]
resOrdered$Name=rownames(resOrdered)

library(dplyr)
resOrdered.Sig=data.frame(resOrdered[1:sigGenes ,])
resOrdered.Sig=resOrdered.Sig[c(7,1:6)]
# resOrdered.Sig=left_join(resOrdered.Sig, tmp.countData, by="Name")
# resOrdered.Sig=left_join(resOrdered.Sig, day.counts.ordered, by="Name") %>% select(-c(Rank,Sample))
# resOrdered.Sig=left_join(resOrdered.Sig, night.counts.ordered, by="Name") %>% select(-c(Rank,Sample))
# resOrdered.Sig=left_join(resOrdered.Sig, annotation, by="Name")
# colnames(resOrdered.Sig)[14:19]=c("Day_Total", "Day_Mean", "Day_SE", "Night_Total", "Night_Mean", "Night_SE")
# 
# write.table(as.data.frame(resOrdered.Sig), sep="\t",file="data/results.tsv", quote = FALSE, row.names =FALSE)
# 
# library(knitr)
# resOrdered.Sig %>% 
# 	select(c(1,3,7,20,21)) %>% 
# 	kable(.)
```


### Log2Fold vs Rank(p-value adjusted) Plot
```{r}
ranked.sig.data=resOrdered.Sig %>%
	arrange(padj,desc(abs(log2FoldChange))) %>% 
	mutate(Rank=row_number(padj))

# ranked.sig.data %>% 
# 	ggplot(aes(Rank,log2FoldChange)) +
# 	xlab("Rank by adjusted p-values") +
# 	ylab("Log2 Fold Change") +
# 	geom_point() +
# 	geom_text(aes(label=IMG_Source), vjust=-4)+
# 	geom_errorbar(aes(ymax=log2FoldChange+lfcSE, ymin=log2FoldChange-lfcSE)) +
# 	geom_hline(aes(yintercept=0), linetype=2,color="red") +
# 	theme_minimal()
```

### Volcano (log10(padj) vs log2FoldChange)

```{r}
plot(-log10(padj) ~ log2FoldChange, as.data.frame(res), pch=20)
```

## Session Info

```{r session_info}
sessionInfo()
```
